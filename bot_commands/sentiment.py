import re
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from telethon import TelegramClient
from telethon.errors import MessageIdInvalidError
from init_settings.config import api_id, api_hash, session_path

# === –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å: Blanchefort (—Ç–æ—á–Ω–µ–µ, –Ω–æ —Ç—è–∂–µ–ª–µ–µ) ===
base_model_name = "blanchefort/rubert-base-cased-sentiment"
base_tokenizer = AutoTokenizer.from_pretrained(base_model_name)
base_model = AutoModelForSequenceClassification.from_pretrained(base_model_name)
labels = ['negative', 'neutral', 'positive']

# === –†–µ–∑–µ—Ä–≤–Ω–∞—è –º–æ–¥–µ–ª—å: Cointegrated (–ª—ë–≥–∫–∞—è) ===
fallback_model_name = "cointegrated/rubert-tiny-sentiment-balanced"
fallback_tokenizer = AutoTokenizer.from_pretrained(fallback_model_name)
fallback_model = AutoModelForSequenceClassification.from_pretrained(fallback_model_name)

# === –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ä—É—á–Ω–æ–π –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ ===
NEGATIVE_KEYWORDS = ["–ø—Ä–æ–≤–∞–ª", "—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ", "—Å–∞–Ω–∫—Ü–∏", "–Ω–µ –±—É–¥–µ—Ç", "–æ—Ç–∫–∞–∑", "–∞–≤–∞—Ä–∏—è", "—Å–Ω–∏–∑–∏–ª—Å—è"]

# === –ê–Ω–∞–ª–∏–∑ —Å –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª—å—é ===
def run_model(text: str, tokenizer, model) -> tuple[str, float]:
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
    with torch.no_grad():
        logits = model(**inputs).logits
    probs = torch.nn.functional.softmax(logits, dim=-1).squeeze().numpy()
    top = int(np.argmax(probs))
    return labels[top], probs[top]

# === –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ ===
def analyze_sentiment(text: str) -> str:
    try:
        label, score = run_model(text, base_tokenizer, base_model)

        # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∏–∑–∫–∞—è ‚Äî –ø–æ–¥–∫–ª—é—á–∞–µ–º fallback-–º–æ–¥–µ–ª—å
        if score < 0.75:
            label, score = run_model(text, fallback_tokenizer, fallback_model)

        # –†—É—á–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è: –µ—Å–ª–∏ —Å–ª–æ–≤–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ, –∞ –º–µ—Ç–∫–∞ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è
        lowered = text.lower()
        if label == "neutral" and any(word in lowered for word in NEGATIVE_KEYWORDS):
            label = "negative"

        if label == "positive":
            return f"üòä –ü–æ–∑–∏—Ç–∏–≤–Ω–∞—è ({score:.2f})"
        elif label == "neutral":
            return f"üòê –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è ({score:.2f})"
        elif label == "negative":
            return f"üò† –ù–µ–≥–∞—Ç–∏–≤–Ω–∞—è ({score:.2f})"
        else:
            return f"ü§∑ –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å"
    except Exception as e:
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}"

# === –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ Telegram-–ø–æ—Å—Ç–∞ ===
async def extract_text_from_telegram(url: str) -> str:
    match = re.match(r"https?://t\.me/([\w\d_]+)/([0-9]+)", url)
    if not match:
        return "‚ö†Ô∏è –ù–µ–≤–µ—Ä–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ Telegram-–ø–æ—Å—Ç."

    channel_username, msg_id = match.groups()
    msg_id = int(msg_id)

    try:
        async with TelegramClient(session_path, api_id, api_hash) as client:
            message = await client.get_messages(channel_username, ids=msg_id)
            return message.text.strip() if message and message.text else "[–ü–æ—Å—Ç –ø—É—Å—Ç –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω]"
    except MessageIdInvalidError:
        return "[‚õî –°–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ]"
    except Exception as e:
        return f"[‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ Telegram: {e}]"

# === –û–±—ë—Ä—Ç–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ —Å—Å—ã–ª–∫–µ ===
async def analyze_telegram_post(url: str) -> str:
    text = await extract_text_from_telegram(url)
    if text.startswith("[") or text.startswith("‚ö†Ô∏è"):
        return text
    return analyze_sentiment(text)
